{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.0005547706387005746\n",
      "layers.0.0.bias has gradient mean of 0.0008321559871546924\n",
      "layers.1.0.weight has gradient mean of 0.0003348961763549596\n",
      "layers.1.0.bias has gradient mean of 0.0023519687820225954\n",
      "layers.2.0.weight has gradient mean of 0.0020374569576233625\n",
      "layers.2.0.bias has gradient mean of 0.011279369704425335\n",
      "layers.3.0.weight has gradient mean of 0.004004963207989931\n",
      "layers.3.0.bias has gradient mean of 0.034551698714494705\n",
      "layers.4.0.weight has gradient mean of 0.004936755169183016\n",
      "layers.4.0.bias has gradient mean of 0.07026170194149017\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class addConnections(nn.Module):\n",
    "    def __init__(self, add_connections):\n",
    "        super().__init__()\n",
    "        self.add_connections = add_connections\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(3, 3), nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(3, 3), nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(3, 3), nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(3, 3), nn.GELU()),\n",
    "            nn.Sequential(nn.Linear(3, 3), nn.GELU())\n",
    "        ])\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = inputs  # Initialize x with input\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.add_connections:\n",
    "                x = x + layer_output  # Add residual connection\n",
    "            else:\n",
    "                x = layer_output  # Standard forward pass\n",
    "        return x\n",
    "\n",
    "def calculate_gradients(model, x):\n",
    "    x.requires_grad = True  # Ensure the input has requires_grad=True\n",
    "    output = model(x)\n",
    "\n",
    "    target = torch.zeros_like(output)  # Ensure target matches output shape\n",
    "    loss = nn.MSELoss()(output, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:  # Check if gradients are computed\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "        else:\n",
    "            print(f\"{name} has no gradients computed.\")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = addConnections(add_connections=False)\n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]], requires_grad=True)  # Ensure input requires grad\n",
    "calculate_gradients(model_without_shortcut, sample_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.6297153830528259\n",
      "layers.0.0.bias has gradient mean of 0.9445731043815613\n",
      "layers.1.0.weight has gradient mean of 0.5255692005157471\n",
      "layers.1.0.bias has gradient mean of 0.7022299766540527\n",
      "layers.2.0.weight has gradient mean of 0.7472164630889893\n",
      "layers.2.0.bias has gradient mean of 0.9945958256721497\n",
      "layers.3.0.weight has gradient mean of 0.4475112557411194\n",
      "layers.3.0.bias has gradient mean of 0.45861271023750305\n",
      "layers.4.0.weight has gradient mean of 0.5911622047424316\n",
      "layers.4.0.bias has gradient mean of 0.7279775142669678\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_without_shortcut = addConnections(add_connections=True)\n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]], requires_grad=True)  # Ensure input requires grad\n",
    "calculate_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
